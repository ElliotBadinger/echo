# Research Documentation Template

**Version:** 2.0 - Unified Documentation System
**Last Updated:** 2025-09-06
**Purpose:** Standardized research documentation with MCP integration
**Integration:** Used for all research activities and findings

---

## Research Questions

**Primary Research Question**: [What specific question are you trying to answer?]
**Secondary Questions**: [Additional questions that support the primary question]
**Research Scope**: [What areas will and won't be covered]

---

## Methodology

### Research Approach
**Strategy**: [Describe your overall research strategy]
**Sources**: [What types of sources will you use]
**Validation**: [How will you verify the quality of findings]

### MCP Server Usage
**Tools Used**: [List MCP servers and tools used]
**Search Strategy**: [Describe your search and extraction approach]
**Quality Assurance**: [How you ensured research quality]

---

## Findings

### Key Discoveries
**Finding 1**: [Major discovery from research]
- **Source**: [Where this finding came from]
- **Evidence**: [Supporting evidence]
- **Impact**: [How this affects the project]

**Finding 2**: [Another major discovery]
- **Source**: [Where this finding came from]
- **Evidence**: [Supporting evidence]
- **Impact**: [How this affects the project]

### Research Quality Assessment
**Source Credibility**: [Assessment of source reliability]
**Information Currency**: [How up-to-date is the information]
**Practical Applicability**: [How applicable to our project]

---

## Implementation

### Recommended Actions
**Action 1**: [Specific implementation recommendation]
- **Rationale**: [Why this action is recommended]
- **Expected Outcome**: [What result is expected]
- **Timeline**: [When this should be implemented]

**Action 2**: [Another implementation recommendation]
- **Rationale**: [Why this action is recommended]
- **Expected Outcome**: [What result is expected]
- **Timeline**: [When this should be implemented]

### Risk Assessment
**Technical Risks**: [Potential technical challenges]
**Implementation Risks**: [Potential implementation challenges]
**Mitigation Strategies**: [How to address identified risks]

---

## Research Overview

**Research ID**: [RESEARCH_YYYYMMDD_HHMM]
**Topic**: [Specific research topic or question]
**Researcher**: [Agent or team member conducting research]
**Date**: [YYYY-MM-DD]
**Duration**: [Time spent on research]

---

## Research Objectives

### Primary Objective
**[Specific research question or problem to solve]**
- **Scope**: [What aspects will be researched]
- **Depth**: [Level of detail required]
- **Timeline**: [Research completion timeline]

### Secondary Objectives
1. **[Objective 1]**: [Related research goal]
2. **[Objective 2]**: [Supporting research goal]

### Success Criteria
- [ ] **Information Quality**: Find credible, current sources
- [ ] **Completeness**: Address all aspects of research question
- [ ] **Practical Value**: Findings applicable to implementation
- [ ] **Actionability**: Clear recommendations from research

---

## Research Methodology

### MCP Server Strategy

#### Brave Search - Broad Research
**Purpose**: Identify state-of-the-art approaches and research
**Query Strategy**:
- [Query 1]: [Specific search terms, expected results]
- [Query 2]: [Refined search terms, expected results]
- [Query 3]: [Alternative search terms, expected results]

**Expected Outcomes**:
- Current best practices and techniques
- Research papers and scholarly articles
- Industry case studies and benchmarks

#### Context7 - Implementation Guidance
**Purpose**: Get current Android documentation and examples
**Library Strategy**:
- [/android/core]: [Core Android APIs to research]
- [/android/jetpack]: [Jetpack components to investigate]
- [/android/kotlin]: [Kotlin-specific patterns and practices]

**Expected Outcomes**:
- Current API documentation
- Code examples and best practices
- Implementation patterns and guidelines

#### Playwright - Comprehensive Extraction
**Purpose**: Extract complete documentation from web sources
**Source Strategy**:
- [Source 1]: [Official documentation sites]
- [Source 2]: [Research paper repositories]
- [Source 3]: [Technical blog and tutorial sites]

**Expected Outcomes**:
- Complete technical documentation
- Research papers and academic content
- Implementation tutorials and guides

#### GitHub MCP - Validation
**Purpose**: Validate findings through repository analysis
**Validation Strategy**:
- Repository structure analysis
- CI/CD pipeline review
- Implementation pattern validation
- Performance benchmark analysis

### Research Phases

#### Phase 1: Discovery (2-4 hours)
- [ ] Conduct broad searches with Brave Search
- [ ] Identify key research areas and sources
- [ ] Assess source credibility and recency
- [ ] Document initial findings and insights

#### Phase 2: Deep Dive (4-6 hours)
- [ ] Extract comprehensive content with Playwright
- [ ] Get detailed documentation with Context7
- [ ] Analyze implementation patterns
- [ ] Cross-reference multiple sources

#### Phase 3: Synthesis (2-3 hours)
- [ ] Combine findings from all sources
- [ ] Identify patterns and best practices
- [ ] Develop implementation recommendations
- [ ] Create actionable insights

---

## Research Findings

### Brave Search Results

#### Query Results Summary
| Query | Results Found | Relevance Score | Key Insights | Implementation Value |
|-------|---------------|-----------------|--------------|---------------------|
| [Query 1] | [Count] | [1-10] | [Summary] | [High/Med/Low] |
| [Query 2] | [Count] | [1-10] | [Summary] | [High/Med/Low] |
| [Query 3] | [Count] | [1-10] | [Summary] | [High/Med/Low] |

#### Key Findings from Brave Search
1. **[Topic/Area]**: [Key insight, source credibility, practical application]
   - **Source**: [URL, publication date, credibility assessment]
   - **Key Takeaway**: [Most important insight]
   - **Implementation Impact**: [How this informs development]

2. **[Topic/Area]**: [Key insight, source credibility, practical application]
   - **Source**: [URL, publication date, credibility assessment]
   - **Key Takeaway**: [Most important insight]
   - **Implementation Impact**: [How this informs development]

### Context7 Results

#### Documentation Accessed
| Library ID | Topic | Tokens Used | Documentation Quality | Usefulness |
|------------|-------|-------------|----------------------|------------|
| [/library/id] | [Topic] | [Tokens] | [1-10] | [High/Med/Low] |

#### Key Findings from Context7
1. **[Library/Topic]**: [Key documentation insight]
   - **API Details**: [Specific API information found]
   - **Best Practices**: [Recommended implementation patterns]
   - **Code Examples**: [Quality and applicability of examples]

2. **[Library/Topic]**: [Key documentation insight]
   - **API Details**: [Specific API information found]
   - **Best Practices**: [Recommended implementation patterns]
   - **Code Examples**: [Quality and applicability of examples]

### Playwright Results

#### Content Extracted
| Source URL | Content Type | Extraction Quality | Completeness | Research Value |
|------------|--------------|-------------------|--------------|---------------|
| [URL] | [Type] | [1-10] | [Percentage] | [High/Med/Low] |

#### Key Findings from Playwright
1. **[Source/Document]**: [Key content extracted]
   - **Content Quality**: [Assessment of information quality]
   - **Completeness**: [How comprehensive the extraction was]
   - **Practical Value**: [Applicability to research question]

2. **[Source/Document]**: [Key content extracted]
   - **Content Quality**: [Assessment of information quality]
   - **Completeness**: [How comprehensive the extraction was]
   - **Practical Value**: [Applicability to research question]

### GitHub MCP Validation

#### Repository Analysis Results
- **Code Patterns**: [Implementation patterns observed]
- **Architecture Insights**: [Architectural approaches found]
- **Testing Strategies**: [Testing patterns identified]
- **Performance Benchmarks**: [Performance data collected]

---

## Research Synthesis

### Cross-Source Analysis

#### Consistent Findings
**Finding**: [Common insight across multiple sources]
- **Sources**: [Which MCP servers/sources confirmed this]
- **Credibility**: [Strength of evidence]
- **Confidence Level**: [High/Medium/Low]

**Finding**: [Common insight across multiple sources]
- **Sources**: [Which MCP servers/sources confirmed this]
- **Credibility**: [Strength of evidence]
- **Confidence Level**: [High/Medium/Low]

#### Contradictory Findings
**Contradiction**: [Conflicting information found]
- **Source A**: [Position and supporting evidence]
- **Source B**: [Opposing position and supporting evidence]
- **Resolution**: [How contradiction was resolved]
- **Recommendation**: [Suggested approach based on analysis]

### Implementation Recommendations

#### Primary Recommendation
**[Most strongly supported approach]**
- **Rationale**: [Why this is recommended based on research]
- **Supporting Evidence**: [Key findings that support this recommendation]
- **Expected Benefits**: [Anticipated improvements or advantages]
- **Implementation Considerations**: [Requirements and constraints]

#### Alternative Approaches
1. **[Alternative 1]**: [Description and rationale]
   - **Pros**: [Advantages of this approach]
   - **Cons**: [Disadvantages or limitations]
   - **Use Case**: [When this would be preferred]

2. **[Alternative 2]**: [Description and rationale]
   - **Pros**: [Advantages of this approach]
   - **Cons**: [Disadvantages or limitations]
   - **Use Case**: [When this would be preferred]

### Risk Assessment

#### Technical Risks
- **[Risk 1]**: [Potential technical challenge]
  - **Likelihood**: [High/Medium/Low]
  - **Impact**: [High/Medium/Low]
  - **Mitigation**: [Risk reduction strategy]

- **[Risk 2]**: [Potential technical challenge]
  - **Likelihood**: [High/Medium/Low]
  - **Impact**: [High/Medium/Low]
  - **Mitigation**: [Risk reduction strategy]

#### Implementation Risks
- **[Risk 1]**: [Potential implementation challenge]
  - **Likelihood**: [High/Medium/Low]
  - **Impact**: [High/Medium/Low]
  - **Mitigation**: [Risk reduction strategy]

---

## Research Quality Assessment

### Source Credibility Analysis
- **Primary Sources**: [Official documentation, peer-reviewed papers]
  - **Credibility Score**: [1-10]
  - **Recency**: [How current the information is]
  - **Authority**: [Source reputation and expertise]

- **Secondary Sources**: [Technical blogs, community content]
  - **Credibility Score**: [1-10]
  - **Recency**: [How current the information is]
  - **Practical Value**: [Real-world applicability]

### Information Quality Metrics
- **Accuracy**: [1-10 rating of technical correctness]
- **Completeness**: [1-10 rating of information comprehensiveness]
- **Currency**: [1-10 rating of how up-to-date information is]
- **Relevance**: [1-10 rating of applicability to research question]

### Research Effectiveness Metrics
- **Time Efficiency**: [Hours spent vs. value gained]
- **Insight Quality**: [Usefulness of findings for decision-making]
- **Implementation Guidance**: [Clarity of recommendations]
- **Future Value**: [Usefulness for ongoing development]

---

## Actionable Insights

### Immediate Implementation
1. **[Action 1]**: [Specific, immediate step based on research]
   - **Priority**: [High/Medium/Low]
   - **Timeline**: [When to implement]
   - **Expected Impact**: [Anticipated benefit]

2. **[Action 2]**: [Specific, immediate step based on research]
   - **Priority**: [High/Medium/Low]
   - **Timeline**: [When to implement]
   - **Expected Impact**: [Anticipated benefit]

### Medium-term Recommendations
1. **[Recommendation 1]**: [2-4 week implementation]
   - **Rationale**: [Why this timeframe]
   - **Requirements**: [Prerequisites needed]
   - **Success Metrics**: [How to measure success]

2. **[Recommendation 2]**: [2-4 week implementation]
   - **Rationale**: [Why this timeframe]
   - **Requirements**: [Prerequisites needed]
   - **Success Metrics**: [How to measure success]

### Long-term Considerations
1. **[Consideration 1]**: [Strategic insight for future development]
   - **Timeline**: [When this becomes relevant]
   - **Monitoring**: [What to watch for]
   - **Triggers**: [When to revisit this insight]

---

## Research Documentation

### Files Updated
- [ ] `docs/project-state/research-findings.md` - Added research insights
- [ ] `docs/project-state/change-log.md` - Documented research application
- [ ] `docs/frameworks/[relevant-framework].md` - Updated framework guidance

### Research Artifacts
- **Research Notes**: [Location of detailed research notes]
- **Source Materials**: [Location of extracted content]
- **Analysis Documents**: [Location of detailed analysis]
- **Implementation Plans**: [Location of action plans]

### Knowledge Transfer
**Key Insights for Team**:
- [Important finding that should be shared]
- [Best practice that should be adopted]
- [Technical pattern that should be documented]

**Training Recommendations**:
- [Skill or knowledge gap identified]
- [Training resource or approach recommended]
- [Process improvement suggested]

---

## Research Follow-up

### Validation Requirements
- [ ] **Implementation Testing**: Validate research recommendations
- [ ] **Performance Measurement**: Measure impact of implemented changes
- [ ] **User Feedback**: Gather feedback on implemented changes
- [ ] **Iteration Planning**: Plan follow-up research based on results

### Monitoring and Updates
- [ ] **Research Currency**: Monitor for new developments in researched areas
- [ ] **Implementation Tracking**: Track adoption of research recommendations
- [ ] **Effectiveness Assessment**: Measure impact of research-informed changes
- [ ] **Knowledge Updates**: Update team knowledge based on research findings

### Future Research Triggers
- [ ] **Technology Updates**: When new versions of researched technologies are released
- [ ] **Performance Issues**: If implemented solutions don't meet expectations
- [ ] **New Requirements**: When project requirements change significantly
- [ ] **Community Feedback**: When user feedback suggests research updates needed

---

## Research Summary

**Research Question**: [Original research question]
**Primary Finding**: [Most important insight or recommendation]
**Confidence Level**: [High/Medium/Low based on evidence strength]
**Implementation Priority**: [High/Medium/Low based on impact and urgency]
**Next Steps**: [Immediate actions based on research findings]

**Research Effectiveness**:
- **Time Invested**: [Total hours spent]
- **Value Generated**: [Expected impact and benefits]
- **Knowledge Gained**: [New insights and understanding]
- **Process Improvements**: [Research methodology enhancements identified]

---

*This research template ensures comprehensive, MCP-integrated research documentation. Use this format for all research activities to maintain consistency and maximize research value.*